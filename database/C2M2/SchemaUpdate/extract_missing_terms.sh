#!/bin/bash
# Call syntax: ./extract_missing_terms.sh <logfilename> <dbtablename/kw>
# From the log file, extract terms which are in the DCC metadata files but not in the master ontology files
#
# This script is generally located and is run from the folder which contains the scripts folder 
# (which has the python script file prepare_C2M2_submission.py and the folder external_CV_reference_files). 
# If found anywhere else, it is there generally for back up purposes.

logf=$1
kw=$2
outf0=missing_${kw}s
outf=${outf0}.tsv
outf_nh=${outf0}_noheader.tsv
dbtable=$kw

# If DB port changes, edit it here
dbcon_str="-h localhost -p 5433 -U drc -d drc";

#grep 'has no name' schema_update_test.log | grep -o "Term '[^']*'" | sed "s/Term '\(.*\)'/\1/"
#grep 'has no name' $logf | grep -o "Term '[^']*'" | sed "s/Term '\(.*\)'/\1/"

# If these IDs are the older DB table, can get it from there
##ids=$(egrep -e "has no name.*${dbtable}" $logf |awk -F"'" '/Term / {print $2}' | sed "s/.*/'&'/" | tr '\n' ',' | sed 's/,$//')
# The logic changed to capture all missing
# Example row: This is generated by frictionless
#355   │ None  │ foreign-key │ Row at position "355" violates the foreign key: for "compound": values "138394156" not found in the lookup table "compound" as "id" 

#ids=($(egrep -e "violates the foreign key.*${kw}.*values.*not found in the lookup table.*${kw}" $logf | grep -oP 'values "\K[^"]+' | sort | uniq ))
ids=($(egrep -e "violates the foreign key.*${kw}.*values.*not found" $logf | grep -oP 'values "\K[^"]+' | sort | uniq ))

echo "Identified the IDs for missing ${kw}";
echo $ids

# Format for use in psql
ids_string=$(printf "'%s'," "${ids[@]}")
ids_string=${ids_string%,}  # Remove the trailing comma

echo "Formatted string for use in psql:";
echo $ids_string

# Fetch such records from the DB which has metadata from the last submission
# Mano: 2025/08/20: Always run the psal command even if ids_string is just '', so that at least the outf is populated and processing downstream continues
# Below, do not put ${dbcon_str} in double quotes, so that its expansion indeed contains spaces to separate the specs for db server, db port, etc.
psql ${dbcon_str} -c "\copy (SELECT * FROM c2m2.${dbtable} WHERE id IN (${ids_string})) TO '${outf}' WITH (FORMAT csv, DELIMITER E'\t', HEADER);"
echo "Fetched these records from the DB";
# clean synonym column of $outf
cp $outf ${outf}_raw.tsv
tmpf=${outf0}_temp.tsv
awk -F'\t' 'BEGIN { OFS="\t" } { \
    if (NF >= 4) { \
	sub(/^"\[/, "[", $4); \
        sub(/\]"$/, "]", $4); \
	sub(/^\[""\]$/, "[]", $4); \
        gsub(/""/, "\"", $4); \
    } \
    print $0 \
}' $outf > ${tmpf} && mv ${tmpf} $outf

echo "Cleaned up the file $outf";

#-------------------------------
outf_with_searchable="${outf}"_ws.tsv

# if the file missing_proteins.tsv has searchable column, exclude it.
cp "${outf}" "${outf_with_searchable}"

# Apparently, csvkit package does it as: csvcut -t -C searchable protein.tsv > protein_no_searchable.tsv
awk -F'\t' '
NR==1 {
    for (i=1; i<=NF; i++) if ($i=="searchable") skip=i
}
{
    first=1
    for (i=1; i<=NF; i++) if (i != skip) {
        if (!first) printf "\t"
        printf "%s", $i
        first=0
    }
    print ""
}
' "${outf_with_searchable}" > "${outf}"

rm "${outf_with_searchable}"
echo "Excluded the searchable column if it was present";
#-------------------------------

# exclude the header
sed '1d' $outf > ${outf_nh}
echo "Prepared the file without header: ${outf_nh}";
echo "All done!";

